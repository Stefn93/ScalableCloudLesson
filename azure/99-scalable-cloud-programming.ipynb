{"cells":[{"cell_type":"markdown","source":["#Welcome to a random Databricks Python Notebook"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0f4e0a8d-0d48-4a00-8676-030c43cfe2be"}}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) What is Apache Spark?\n\nSpark is a unified processing engine that can analyze big data using SQL, machine learning, graph processing or real-time stream analysis:\n\n![Spark Engines](https://files.training.databricks.com/images/wiki-book/book_intro/spark_4engines.png)\n<br/>\n<br/>\n* At its core is the Spark Engine.\n* The DataFrames API provides an abstraction above RDDs while simultaneously improving performance 5-20x over traditional RDDs with its Catalyst Optimizer.\n* Spark ML provides high quality and finely tuned machine learning algorithms for processing big data.\n* The Graph processing API gives us an easily approachable API for modeling pairwise relationships between people, objects, or nodes in a network.\n* The Streaming APIs give us End-to-End Fault Tolerance, with Exactly-Once semantics, and the possibility for sub-millisecond latency.\n\nAnd it all works together seamlessly!"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1888aa25-7a2f-4cdd-8786-735572b839d3"}}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Scala, Python, Java, R & SQL\n* Besides being able to run in many environments...\n* Apache Spark makes the platform even more approachable by supporting multiple languages:\n  * Scala - Apache Spark's primary language.\n  * Python - More commonly referred to as PySpark\n  * R - <a href=\"https://spark.apache.org/docs/latest/sparkr.html\" target=\"_blank\">SparkR</a> (R on Spark)\n  * Java\n  * SQL - Closer to ANSI SQL 2003 compliance\n    * Now running all 99 TPC-DS queries\n    * New standards-compliant parser (with good error messages!)\n    * Subqueries (correlated & uncorrelated)\n    * Approximate aggregate stats\n* With the older RDD API, there are significant differences with each language's implementation, namely in performance.\n* With the newer DataFrames API, the performance differences between languages are nearly nonexistence (especially for Scala, Java & Python).\n* With that, not all languages get the same amount of love - just the same, that API gap for each language is rapidly closing, especially between Spark 1.x and 2.x.\n\n![RDD vs DataFrames](https://files.training.databricks.com/images/105/rdd-vs-dataframes.png)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b9226ceb-61b3-4cf1-810b-8a273a6d2a4c"}}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) RDDs\n* The primary data abstraction of Spark engine is the RDD: Resilient Distributed Dataset\n  * Resilient, i.e., fault-tolerant with the help of RDD lineage graph and so able to recompute missing or damaged partitions due to node failures.\n  * Distributed with data residing on multiple nodes in a cluster.\n  * Dataset is a collection of partitioned data with primitive values or values of values, e.g., tuples or other objects.\n* The original paper that gave birth to the concept of RDD is <a href=\"https://cs.stanford.edu/~matei/papers/2012/nsdi_spark.pdf\" target=\"_blank\">Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing</a> by Matei Zaharia et al.\n* Today, with Spark 2.x, we treat RDDs as the assembly language of the Spark ecosystem.\n* DataFrames, Datasets & SQL provide the higher level abstraction over RDDs."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"665826f4-cf6c-4a8d-ab67-ddad33093a81"}}},{"cell_type":"markdown","source":["-sandbox\n\n##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) The Cluster: Drivers, Executors, Slots & Tasks\n![Spark Physical Cluster, slots](https://files.training.databricks.com/images/105/spark_cluster_slots.png)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"32ec3383-7807-4083-b9e0-a8748a53a599"}}},{"cell_type":"markdown","source":["### Getting Started\n\nRun the following cell to configure the \"classroom.\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b58ef16a-182c-4366-bed7-1c7852a211ed"}}},{"cell_type":"code","source":["%run ./Includes/Classroom-Setup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8bf77736-4f51-41ec-8868-0e34cee760c3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Initialized classroom variables & functions...","textData":null,"removedWidgets":[],"addedWidgets":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["Initialized classroom variables & functions..."]}}],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n## Spark SQL and DataFrames\n\nSince Spark 2.0, Spark SQL and the DataFrames API have provided analogous entry points to easily manipulate data. DataFrames, tables, and temp views register the necessary metadata to execute Spark logic. The SparkSession uses these metadata to optimize computation while abstracting away many of the considerations about how data will be accessed and distributed during processing.\n\nWhile there are slight differences between how users will interact with DataFrames, tables, and temp views, the following holds true for all:\n- They are built on top of Spark SQL, which simplifies and optimizes Spark execution.\n- They are collections of rows and provide easy access to columnar transformations.\n- Rows will compile down to RDDs at execution.\n- They provide fault-tolerant access to data stored externally.\n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> It is possible to create DataFrames/tables/views directly from RDDs. This course will focus on manipulating files stored in external cloud storage or data being loaded from sources such as relational databases and pub/sub services."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8ca03805-059b-4ed8-99eb-ea897748b1e4"}}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Creating DataFrames by Reading from CSV\n\n### The Data Source\n* For this exercise, use a file called **iris.csv**.\n* This is the canonical [iris dataset](https://archive.ics.uci.edu/ml/datasets/iris).\n* Use **&percnt;fs head ...** to view the first few lines of the file."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"decb4d5a-b178-471d-adf5-3cb015bbcff8"}}},{"cell_type":"code","source":["%fs head /mnt/training/iris/iris.csv"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e337411d-c111-43e5-bc2b-dfa564daade2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">&quot;&quot;,&quot;Sepal.Length&quot;,&quot;Sepal.Width&quot;,&quot;Petal.Length&quot;,&quot;Petal.Width&quot;,&quot;Species&quot;\n&quot;1&quot;,5.1,3.5,1.4,0.2,&quot;setosa&quot;\n&quot;2&quot;,4.9,3,1.4,0.2,&quot;setosa&quot;\n&quot;3&quot;,4.7,3.2,1.3,0.2,&quot;setosa&quot;\n&quot;4&quot;,4.6,3.1,1.5,0.2,&quot;setosa&quot;\n&quot;5&quot;,5,3.6,1.4,0.2,&quot;setosa&quot;\n&quot;6&quot;,5.4,3.9,1.7,0.4,&quot;setosa&quot;\n&quot;7&quot;,4.6,3.4,1.4,0.3,&quot;setosa&quot;\n&quot;8&quot;,5,3.4,1.5,0.2,&quot;setosa&quot;\n&quot;9&quot;,4.4,2.9,1.4,0.2,&quot;setosa&quot;\n&quot;10&quot;,4.9,3.1,1.5,0.1,&quot;setosa&quot;\n&quot;11&quot;,5.4,3.7,1.5,0.2,&quot;setosa&quot;\n&quot;12&quot;,4.8,3.4,1.6,0.2,&quot;setosa&quot;\n&quot;13&quot;,4.8,3,1.4,0.1,&quot;setosa&quot;\n&quot;14&quot;,4.3,3,1.1,0.1,&quot;setosa&quot;\n&quot;15&quot;,5.8,4,1.2,0.2,&quot;setosa&quot;\n&quot;16&quot;,5.7,4.4,1.5,0.4,&quot;setosa&quot;\n&quot;17&quot;,5.4,3.9,1.3,0.4,&quot;setosa&quot;\n&quot;18&quot;,5.1,3.5,1.4,0.3,&quot;setosa&quot;\n&quot;19&quot;,5.7,3.8,1.7,0.3,&quot;setosa&quot;\n&quot;20&quot;,5.1,3.8,1.5,0.3,&quot;setosa&quot;\n&quot;21&quot;,5.4,3.4,1.7,0.2,&quot;setosa&quot;\n&quot;22&quot;,5.1,3.7,1.5,0.4,&quot;setosa&quot;\n&quot;23&quot;,4.6,3.6,1,0.2,&quot;setosa&quot;\n&quot;24&quot;,5.1,3.3,1.7,0.5,&quot;setosa&quot;\n&quot;25&quot;,4.8,3.4,1.9,0.2,&quot;setosa&quot;\n&quot;26&quot;,5,3,1.6,0.2,&quot;setosa&quot;\n&quot;27&quot;,5,3.4,1.6,0.4,&quot;setosa&quot;\n&quot;28&quot;,5.2,3.5,1.5,0.2,&quot;setosa&quot;\n&quot;29&quot;,5.2,3.4,1.4,0.2,&quot;setosa&quot;\n&quot;30&quot;,4.7,3.2,1.6,0.2,&quot;setosa&quot;\n&quot;31&quot;,4.8,3.1,1.6,0.2,&quot;setosa&quot;\n&quot;32&quot;,5.4,3.4,1.5,0.4,&quot;setosa&quot;\n&quot;33&quot;,5.2,4.1,1.5,0.1,&quot;setosa&quot;\n&quot;34&quot;,5.5,4.2,1.4,0.2,&quot;setosa&quot;\n&quot;35&quot;,4.9,3.1,1.5,0.2,&quot;setosa&quot;\n&quot;36&quot;,5,3.2,1.2,0.2,&quot;setosa&quot;\n&quot;37&quot;,5.5,3.5,1.3,0.2,&quot;setosa&quot;\n&quot;38&quot;,4.9,3.6,1.4,0.1,&quot;setosa&quot;\n&quot;39&quot;,4.4,3,1.3,0.2,&quot;setosa&quot;\n&quot;40&quot;,5.1,3.4,1.5,0.2,&quot;setosa&quot;\n&quot;41&quot;,5,3.5,1.3,0.3,&quot;setosa&quot;\n&quot;42&quot;,4.5,2.3,1.3,0.3,&quot;setosa&quot;\n&quot;43&quot;,4.4,3.2,1.3,0.2,&quot;setosa&quot;\n&quot;44&quot;,5,3.5,1.6,0.6,&quot;setosa&quot;\n&quot;45&quot;,5.1,3.8,1.9,0.4,&quot;setosa&quot;\n&quot;46&quot;,4.8,3,1.4,0.3,&quot;setosa&quot;\n&quot;47&quot;,5.1,3.8,1.6,0.2,&quot;setosa&quot;\n&quot;48&quot;,4.6,3.2,1.4,0.2,&quot;setosa&quot;\n&quot;49&quot;,5.3,3.7,1.5,0.2,&quot;setosa&quot;\n&quot;50&quot;,5,3.3,1.4,0.2,&quot;setosa&quot;\n&quot;51&quot;,7,3.2,4.7,1.4,&quot;versicolor&quot;\n&quot;52&quot;,6.4,3.2,4.5,1.5,&quot;versicolor&quot;\n&quot;53&quot;,6.9,3.1,4.9,1.5,&quot;versicolor&quot;\n&quot;54&quot;,5.5,2.3,4,1.3,&quot;versicolor&quot;\n&quot;55&quot;,6.5,2.8,4.6,1.5,&quot;versicolor&quot;\n&quot;56&quot;,5.7,2.8,4.5,1.3,&quot;versicolor&quot;\n&quot;57&quot;,6.3,3.3,4.7,1.6,&quot;versicolor&quot;\n&quot;58&quot;,4.9,2.4,3.3,1,&quot;versicolor&quot;\n&quot;59&quot;,6.6,2.9,4.6,1.3,&quot;versicolor&quot;\n&quot;60&quot;,5.2,2.7,3.9,1.4,&quot;versicolor&quot;\n&quot;61&quot;,5,2,3.5,1,&quot;versicolor&quot;\n&quot;62&quot;,5.9,3,4.2,1.5,&quot;versicolor&quot;\n&quot;63&quot;,6,2.2,4,1,&quot;versicolor&quot;\n&quot;64&quot;,6.1,2.9,4.7,1.4,&quot;versicolor&quot;\n&quot;65&quot;,5.6,2.9,3.6,1.3,&quot;versicolor&quot;\n&quot;66&quot;,6.7,3.1,4.4,1.4,&quot;versicolor&quot;\n&quot;67&quot;,5.6,3,4.5,1.5,&quot;versicolor&quot;\n&quot;68&quot;,5.8,2.7,4.1,1,&quot;versicolor&quot;\n&quot;69&quot;,6.2,2.2,4.5,1.5,&quot;versicolor&quot;\n&quot;70&quot;,5.6,2.5,3.9,1.1,&quot;versicolor&quot;\n&quot;71&quot;,5.9,3.2,4.8,1.8,&quot;versicolor&quot;\n&quot;72&quot;,6.1,2.8,4,1.3,&quot;versicolor&quot;\n&quot;73&quot;,6.3,2.5,4.9,1.5,&quot;versicolor&quot;\n&quot;74&quot;,6.1,2.8,4.7,1.2,&quot;versicolor&quot;\n&quot;75&quot;,6.4,2.9,4.3,1.3,&quot;versicolor&quot;\n&quot;76&quot;,6.6,3,4.4,1.4,&quot;versicolor&quot;\n&quot;77&quot;,6.8,2.8,4.8,1.4,&quot;versicolor&quot;\n&quot;78&quot;,6.7,3,5,1.7,&quot;versicolor&quot;\n&quot;79&quot;,6,2.9,4.5,1.5,&quot;versicolor&quot;\n&quot;80&quot;,5.7,2.6,3.5,1,&quot;versicolor&quot;\n&quot;81&quot;,5.5,2.4,3.8,1.1,&quot;versicolor&quot;\n&quot;82&quot;,5.5,2.4,3.7,1,&quot;versicolor&quot;\n&quot;83&quot;,5.8,2.7,3.9,1.2,&quot;versicolor&quot;\n&quot;84&quot;,6,2.7,5.1,1.6,&quot;versicolor&quot;\n&quot;85&quot;,5.4,3,4.5,1.5,&quot;versicolor&quot;\n&quot;86&quot;,6,3.4,4.5,1.6,&quot;versicolor&quot;\n&quot;87&quot;,6.7,3.1,4.7,1.5,&quot;versicolor&quot;\n&quot;88&quot;,6.3,2.3,4.4,1.3,&quot;versicolor&quot;\n&quot;89&quot;,5.6,3,4.1,1.3,&quot;versicolor&quot;\n&quot;90&quot;,5.5,2.5,4,1.3,&quot;versicolor&quot;\n&quot;91&quot;,5.5,2.6,4.4,1.2,&quot;versicolor&quot;\n&quot;92&quot;,6.1,3,4.6,1.4,&quot;versicolor&quot;\n&quot;93&quot;,5.8,2.6,4,1.2,&quot;versicolor&quot;\n&quot;94&quot;,5,2.3,3.3,1,&quot;versicolor&quot;\n&quot;95&quot;,5.6,2.7,4.2,1.3,&quot;versicolor&quot;\n&quot;96&quot;,5.7,3,4.2,1.2,&quot;versicolor&quot;\n&quot;97&quot;,5.7,2.9,4.2,1.3,&quot;versicolor&quot;\n&quot;98&quot;,6.2,2.9,4.3,1.3,&quot;versicolor&quot;\n&quot;99&quot;,5.1,2.5,3,1.1,&quot;versicolor&quot;\n&quot;100&quot;,5.7,2.8,4.1,1.3,&quot;versicolor&quot;\n&quot;101&quot;,6.3,3.3,6,2.5,&quot;virginica&quot;\n&quot;102&quot;,5.8,2.7,5.1,1.9,&quot;virginica&quot;\n&quot;103&quot;,7.1,3,5.9,2.1,&quot;virginica&quot;\n&quot;104&quot;,6.3,2.9,5.6,1.8,&quot;virginica&quot;\n&quot;105&quot;,6.5,3,5.8,2.2,&quot;virginica&quot;\n&quot;106&quot;,7.6,3,6.6,2.1,&quot;virginica&quot;\n&quot;107&quot;,4.9,2.5,4.5,1.7,&quot;virginica&quot;\n&quot;108&quot;,7.3,2.9,6.3,1.8,&quot;virginica&quot;\n&quot;109&quot;,6.7,2.5,5.8,1.8,&quot;virginica&quot;\n&quot;110&quot;,7.2,3.6,6.1,2.5,&quot;virginica&quot;\n&quot;111&quot;,6.5,3.2,5.1,2,&quot;virginica&quot;\n&quot;112&quot;,6.4,2.7,5.3,1.9,&quot;virginica&quot;\n&quot;113&quot;,6.8,3,5.5,2.1,&quot;virginica&quot;\n&quot;114&quot;,5.7,2.5,5,2,&quot;virginica&quot;\n&quot;115&quot;,5.8,2.8,5.1,2.4,&quot;virginica&quot;\n&quot;116&quot;,6.4,3.2,5.3,2.3,&quot;virginica&quot;\n&quot;117&quot;,6.5,3,5.5,1.8,&quot;virginica&quot;\n&quot;118&quot;,7.7,3.8,6.7,2.2,&quot;virginica&quot;\n&quot;119&quot;,7.7,2.6,6.9,2.3,&quot;virginica&quot;\n&quot;120&quot;,6,2.2,5,1.5,&quot;virginica&quot;\n&quot;121&quot;,6.9,3.2,5.7,2.3,&quot;virginica&quot;\n&quot;122&quot;,5.6,2.8,4.9,2,&quot;virginica&quot;\n&quot;123&quot;,7.7,2.8,6.7,2,&quot;virginica&quot;\n&quot;124&quot;,6.3,2.7,4.9,1.8,&quot;virginica&quot;\n&quot;125&quot;,6.7,3.3,5.7,2.1,&quot;virginica&quot;\n&quot;126&quot;,7.2,3.2,6,1.8,&quot;virginica&quot;\n&quot;127&quot;,6.2,2.8,4.8,1.8,&quot;virginica&quot;\n&quot;128&quot;,6.1,3,4.9,1.8,&quot;virginica&quot;\n&quot;129&quot;,6.4,2.8,5.6,2.1,&quot;virginica&quot;\n&quot;130&quot;,7.2,3,5.8,1.6,&quot;virginica&quot;\n&quot;131&quot;,7.4,2.8,6.1,1.9,&quot;virginica&quot;\n&quot;132&quot;,7.9,3.8,6.4,2,&quot;virginica&quot;\n&quot;133&quot;,6.4,2.8,5.6,2.2,&quot;virginica&quot;\n&quot;134&quot;,6.3,2.8,5.1,1.5,&quot;virginica&quot;\n&quot;135&quot;,6.1,2.6,5.6,1.4,&quot;virginica&quot;\n&quot;136&quot;,7.7,3,6.1,2.3,&quot;virginica&quot;\n&quot;137&quot;,6.3,3.4,5.6,2.4,&quot;virginica&quot;\n&quot;138&quot;,6.4,3.1,5.5,1.8,&quot;virginica&quot;\n&quot;139&quot;,6,3,4.8,1.8,&quot;virginica&quot;\n&quot;140&quot;,6.9,3.1,5.4,2.1,&quot;virginica&quot;\n&quot;141&quot;,6.7,3.1,5.6,2.4,&quot;virginica&quot;\n&quot;142&quot;,6.9,3.1,5.1,2.3,&quot;virginica&quot;\n&quot;143&quot;,5.8,2.7,5.1,1.9,&quot;virginica&quot;\n&quot;144&quot;,6.8,3.2,5.9,2.3,&quot;virginica&quot;\n&quot;145&quot;,6.7,3.3,5.7,2.5,&quot;virginica&quot;\n&quot;146&quot;,6.7,3,5.2,2.3,&quot;virginica&quot;\n&quot;147&quot;,6.3,2.5,5,1.9,&quot;virginica&quot;\n&quot;148&quot;,6.5,3,5.2,2,&quot;virginica&quot;\n&quot;149&quot;,6.2,3.4,5.4,2.3,&quot;virginica&quot;\n&quot;150&quot;,5.9,3,5.1,1.8,&quot;virginica&quot;\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&quot;&quot;,&quot;Sepal.Length&quot;,&quot;Sepal.Width&quot;,&quot;Petal.Length&quot;,&quot;Petal.Width&quot;,&quot;Species&quot;\n&quot;1&quot;,5.1,3.5,1.4,0.2,&quot;setosa&quot;\n&quot;2&quot;,4.9,3,1.4,0.2,&quot;setosa&quot;\n&quot;3&quot;,4.7,3.2,1.3,0.2,&quot;setosa&quot;\n&quot;4&quot;,4.6,3.1,1.5,0.2,&quot;setosa&quot;\n&quot;5&quot;,5,3.6,1.4,0.2,&quot;setosa&quot;\n&quot;6&quot;,5.4,3.9,1.7,0.4,&quot;setosa&quot;\n&quot;7&quot;,4.6,3.4,1.4,0.3,&quot;setosa&quot;\n&quot;8&quot;,5,3.4,1.5,0.2,&quot;setosa&quot;\n&quot;9&quot;,4.4,2.9,1.4,0.2,&quot;setosa&quot;\n&quot;10&quot;,4.9,3.1,1.5,0.1,&quot;setosa&quot;\n&quot;11&quot;,5.4,3.7,1.5,0.2,&quot;setosa&quot;\n&quot;12&quot;,4.8,3.4,1.6,0.2,&quot;setosa&quot;\n&quot;13&quot;,4.8,3,1.4,0.1,&quot;setosa&quot;\n&quot;14&quot;,4.3,3,1.1,0.1,&quot;setosa&quot;\n&quot;15&quot;,5.8,4,1.2,0.2,&quot;setosa&quot;\n&quot;16&quot;,5.7,4.4,1.5,0.4,&quot;setosa&quot;\n&quot;17&quot;,5.4,3.9,1.3,0.4,&quot;setosa&quot;\n&quot;18&quot;,5.1,3.5,1.4,0.3,&quot;setosa&quot;\n&quot;19&quot;,5.7,3.8,1.7,0.3,&quot;setosa&quot;\n&quot;20&quot;,5.1,3.8,1.5,0.3,&quot;setosa&quot;\n&quot;21&quot;,5.4,3.4,1.7,0.2,&quot;setosa&quot;\n&quot;22&quot;,5.1,3.7,1.5,0.4,&quot;setosa&quot;\n&quot;23&quot;,4.6,3.6,1,0.2,&quot;setosa&quot;\n&quot;24&quot;,5.1,3.3,1.7,0.5,&quot;setosa&quot;\n&quot;25&quot;,4.8,3.4,1.9,0.2,&quot;setosa&quot;\n&quot;26&quot;,5,3,1.6,0.2,&quot;setosa&quot;\n&quot;27&quot;,5,3.4,1.6,0.4,&quot;setosa&quot;\n&quot;28&quot;,5.2,3.5,1.5,0.2,&quot;setosa&quot;\n&quot;29&quot;,5.2,3.4,1.4,0.2,&quot;setosa&quot;\n&quot;30&quot;,4.7,3.2,1.6,0.2,&quot;setosa&quot;\n&quot;31&quot;,4.8,3.1,1.6,0.2,&quot;setosa&quot;\n&quot;32&quot;,5.4,3.4,1.5,0.4,&quot;setosa&quot;\n&quot;33&quot;,5.2,4.1,1.5,0.1,&quot;setosa&quot;\n&quot;34&quot;,5.5,4.2,1.4,0.2,&quot;setosa&quot;\n&quot;35&quot;,4.9,3.1,1.5,0.2,&quot;setosa&quot;\n&quot;36&quot;,5,3.2,1.2,0.2,&quot;setosa&quot;\n&quot;37&quot;,5.5,3.5,1.3,0.2,&quot;setosa&quot;\n&quot;38&quot;,4.9,3.6,1.4,0.1,&quot;setosa&quot;\n&quot;39&quot;,4.4,3,1.3,0.2,&quot;setosa&quot;\n&quot;40&quot;,5.1,3.4,1.5,0.2,&quot;setosa&quot;\n&quot;41&quot;,5,3.5,1.3,0.3,&quot;setosa&quot;\n&quot;42&quot;,4.5,2.3,1.3,0.3,&quot;setosa&quot;\n&quot;43&quot;,4.4,3.2,1.3,0.2,&quot;setosa&quot;\n&quot;44&quot;,5,3.5,1.6,0.6,&quot;setosa&quot;\n&quot;45&quot;,5.1,3.8,1.9,0.4,&quot;setosa&quot;\n&quot;46&quot;,4.8,3,1.4,0.3,&quot;setosa&quot;\n&quot;47&quot;,5.1,3.8,1.6,0.2,&quot;setosa&quot;\n&quot;48&quot;,4.6,3.2,1.4,0.2,&quot;setosa&quot;\n&quot;49&quot;,5.3,3.7,1.5,0.2,&quot;setosa&quot;\n&quot;50&quot;,5,3.3,1.4,0.2,&quot;setosa&quot;\n&quot;51&quot;,7,3.2,4.7,1.4,&quot;versicolor&quot;\n&quot;52&quot;,6.4,3.2,4.5,1.5,&quot;versicolor&quot;\n&quot;53&quot;,6.9,3.1,4.9,1.5,&quot;versicolor&quot;\n&quot;54&quot;,5.5,2.3,4,1.3,&quot;versicolor&quot;\n&quot;55&quot;,6.5,2.8,4.6,1.5,&quot;versicolor&quot;\n&quot;56&quot;,5.7,2.8,4.5,1.3,&quot;versicolor&quot;\n&quot;57&quot;,6.3,3.3,4.7,1.6,&quot;versicolor&quot;\n&quot;58&quot;,4.9,2.4,3.3,1,&quot;versicolor&quot;\n&quot;59&quot;,6.6,2.9,4.6,1.3,&quot;versicolor&quot;\n&quot;60&quot;,5.2,2.7,3.9,1.4,&quot;versicolor&quot;\n&quot;61&quot;,5,2,3.5,1,&quot;versicolor&quot;\n&quot;62&quot;,5.9,3,4.2,1.5,&quot;versicolor&quot;\n&quot;63&quot;,6,2.2,4,1,&quot;versicolor&quot;\n&quot;64&quot;,6.1,2.9,4.7,1.4,&quot;versicolor&quot;\n&quot;65&quot;,5.6,2.9,3.6,1.3,&quot;versicolor&quot;\n&quot;66&quot;,6.7,3.1,4.4,1.4,&quot;versicolor&quot;\n&quot;67&quot;,5.6,3,4.5,1.5,&quot;versicolor&quot;\n&quot;68&quot;,5.8,2.7,4.1,1,&quot;versicolor&quot;\n&quot;69&quot;,6.2,2.2,4.5,1.5,&quot;versicolor&quot;\n&quot;70&quot;,5.6,2.5,3.9,1.1,&quot;versicolor&quot;\n&quot;71&quot;,5.9,3.2,4.8,1.8,&quot;versicolor&quot;\n&quot;72&quot;,6.1,2.8,4,1.3,&quot;versicolor&quot;\n&quot;73&quot;,6.3,2.5,4.9,1.5,&quot;versicolor&quot;\n&quot;74&quot;,6.1,2.8,4.7,1.2,&quot;versicolor&quot;\n&quot;75&quot;,6.4,2.9,4.3,1.3,&quot;versicolor&quot;\n&quot;76&quot;,6.6,3,4.4,1.4,&quot;versicolor&quot;\n&quot;77&quot;,6.8,2.8,4.8,1.4,&quot;versicolor&quot;\n&quot;78&quot;,6.7,3,5,1.7,&quot;versicolor&quot;\n&quot;79&quot;,6,2.9,4.5,1.5,&quot;versicolor&quot;\n&quot;80&quot;,5.7,2.6,3.5,1,&quot;versicolor&quot;\n&quot;81&quot;,5.5,2.4,3.8,1.1,&quot;versicolor&quot;\n&quot;82&quot;,5.5,2.4,3.7,1,&quot;versicolor&quot;\n&quot;83&quot;,5.8,2.7,3.9,1.2,&quot;versicolor&quot;\n&quot;84&quot;,6,2.7,5.1,1.6,&quot;versicolor&quot;\n&quot;85&quot;,5.4,3,4.5,1.5,&quot;versicolor&quot;\n&quot;86&quot;,6,3.4,4.5,1.6,&quot;versicolor&quot;\n&quot;87&quot;,6.7,3.1,4.7,1.5,&quot;versicolor&quot;\n&quot;88&quot;,6.3,2.3,4.4,1.3,&quot;versicolor&quot;\n&quot;89&quot;,5.6,3,4.1,1.3,&quot;versicolor&quot;\n&quot;90&quot;,5.5,2.5,4,1.3,&quot;versicolor&quot;\n&quot;91&quot;,5.5,2.6,4.4,1.2,&quot;versicolor&quot;\n&quot;92&quot;,6.1,3,4.6,1.4,&quot;versicolor&quot;\n&quot;93&quot;,5.8,2.6,4,1.2,&quot;versicolor&quot;\n&quot;94&quot;,5,2.3,3.3,1,&quot;versicolor&quot;\n&quot;95&quot;,5.6,2.7,4.2,1.3,&quot;versicolor&quot;\n&quot;96&quot;,5.7,3,4.2,1.2,&quot;versicolor&quot;\n&quot;97&quot;,5.7,2.9,4.2,1.3,&quot;versicolor&quot;\n&quot;98&quot;,6.2,2.9,4.3,1.3,&quot;versicolor&quot;\n&quot;99&quot;,5.1,2.5,3,1.1,&quot;versicolor&quot;\n&quot;100&quot;,5.7,2.8,4.1,1.3,&quot;versicolor&quot;\n&quot;101&quot;,6.3,3.3,6,2.5,&quot;virginica&quot;\n&quot;102&quot;,5.8,2.7,5.1,1.9,&quot;virginica&quot;\n&quot;103&quot;,7.1,3,5.9,2.1,&quot;virginica&quot;\n&quot;104&quot;,6.3,2.9,5.6,1.8,&quot;virginica&quot;\n&quot;105&quot;,6.5,3,5.8,2.2,&quot;virginica&quot;\n&quot;106&quot;,7.6,3,6.6,2.1,&quot;virginica&quot;\n&quot;107&quot;,4.9,2.5,4.5,1.7,&quot;virginica&quot;\n&quot;108&quot;,7.3,2.9,6.3,1.8,&quot;virginica&quot;\n&quot;109&quot;,6.7,2.5,5.8,1.8,&quot;virginica&quot;\n&quot;110&quot;,7.2,3.6,6.1,2.5,&quot;virginica&quot;\n&quot;111&quot;,6.5,3.2,5.1,2,&quot;virginica&quot;\n&quot;112&quot;,6.4,2.7,5.3,1.9,&quot;virginica&quot;\n&quot;113&quot;,6.8,3,5.5,2.1,&quot;virginica&quot;\n&quot;114&quot;,5.7,2.5,5,2,&quot;virginica&quot;\n&quot;115&quot;,5.8,2.8,5.1,2.4,&quot;virginica&quot;\n&quot;116&quot;,6.4,3.2,5.3,2.3,&quot;virginica&quot;\n&quot;117&quot;,6.5,3,5.5,1.8,&quot;virginica&quot;\n&quot;118&quot;,7.7,3.8,6.7,2.2,&quot;virginica&quot;\n&quot;119&quot;,7.7,2.6,6.9,2.3,&quot;virginica&quot;\n&quot;120&quot;,6,2.2,5,1.5,&quot;virginica&quot;\n&quot;121&quot;,6.9,3.2,5.7,2.3,&quot;virginica&quot;\n&quot;122&quot;,5.6,2.8,4.9,2,&quot;virginica&quot;\n&quot;123&quot;,7.7,2.8,6.7,2,&quot;virginica&quot;\n&quot;124&quot;,6.3,2.7,4.9,1.8,&quot;virginica&quot;\n&quot;125&quot;,6.7,3.3,5.7,2.1,&quot;virginica&quot;\n&quot;126&quot;,7.2,3.2,6,1.8,&quot;virginica&quot;\n&quot;127&quot;,6.2,2.8,4.8,1.8,&quot;virginica&quot;\n&quot;128&quot;,6.1,3,4.9,1.8,&quot;virginica&quot;\n&quot;129&quot;,6.4,2.8,5.6,2.1,&quot;virginica&quot;\n&quot;130&quot;,7.2,3,5.8,1.6,&quot;virginica&quot;\n&quot;131&quot;,7.4,2.8,6.1,1.9,&quot;virginica&quot;\n&quot;132&quot;,7.9,3.8,6.4,2,&quot;virginica&quot;\n&quot;133&quot;,6.4,2.8,5.6,2.2,&quot;virginica&quot;\n&quot;134&quot;,6.3,2.8,5.1,1.5,&quot;virginica&quot;\n&quot;135&quot;,6.1,2.6,5.6,1.4,&quot;virginica&quot;\n&quot;136&quot;,7.7,3,6.1,2.3,&quot;virginica&quot;\n&quot;137&quot;,6.3,3.4,5.6,2.4,&quot;virginica&quot;\n&quot;138&quot;,6.4,3.1,5.5,1.8,&quot;virginica&quot;\n&quot;139&quot;,6,3,4.8,1.8,&quot;virginica&quot;\n&quot;140&quot;,6.9,3.1,5.4,2.1,&quot;virginica&quot;\n&quot;141&quot;,6.7,3.1,5.6,2.4,&quot;virginica&quot;\n&quot;142&quot;,6.9,3.1,5.1,2.3,&quot;virginica&quot;\n&quot;143&quot;,5.8,2.7,5.1,1.9,&quot;virginica&quot;\n&quot;144&quot;,6.8,3.2,5.9,2.3,&quot;virginica&quot;\n&quot;145&quot;,6.7,3.3,5.7,2.5,&quot;virginica&quot;\n&quot;146&quot;,6.7,3,5.2,2.3,&quot;virginica&quot;\n&quot;147&quot;,6.3,2.5,5,1.9,&quot;virginica&quot;\n&quot;148&quot;,6.5,3,5.2,2,&quot;virginica&quot;\n&quot;149&quot;,6.2,3.4,5.4,2.3,&quot;virginica&quot;\n&quot;150&quot;,5.9,3,5.1,1.8,&quot;virginica&quot;\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n### Read the CSV File\nThe following is standard syntax for loading data to DataFrames, here with a few options specifically set for CSV files.\n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> The default delimiter for reading CSV is a comma(`,`), but this is possible to change with the option `\"delimiter\"` to extend this method to cover files using pipes, semi-colons, tabs, or other custom separators."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"63bf1f45-6508-4447-980d-3f761a77ec7e"}}},{"cell_type":"code","source":["csvFilePath = \"/mnt/training/iris/iris.csv\"\n\ntempDF = (spark.read\n  .format(\"csv\")\n  .option(\"header\", True)\n  .option(\"inferSchema\", True)\n  .load(csvFilePath))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5503277d-04c1-4bf4-88fc-029368835b5c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"tempDF","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"_c0","nullable":true,"type":"integer"},{"metadata":{},"name":"Sepal.Length","nullable":true,"type":"double"},{"metadata":{},"name":"Sepal.Width","nullable":true,"type":"double"},{"metadata":{},"name":"Petal.Length","nullable":true,"type":"double"},{"metadata":{},"name":"Petal.Width","nullable":true,"type":"double"},{"metadata":{},"name":"Species","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n### Note the options being used\n\n#### `format`\n- The `format` method specifies what type of data is being loaded.\n- The default format in Spark is Parquet.\n- This method provides access to dozens of file formats, as well as connections to a multitude of connected services; a fairly complete list is available [here](https://docs.databricks.com/data/data-sources/index.html).\n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> Some formats have named methods (`json`, `csv`, `parquet`) that can be used in place of `load(filePath)`, e.g., `spark.read.csv(filePath)`. These methods are analogous to specifying the format using the `format` method, but less extensible.\n\n#### `\"header\"`\n- The `\"header\"` option tells the DataFrame to use the first row for column names.\n- Without this option, columns will be assigned anonymous names `_c0`, `_c1`, ... `_cN`.\n- The `DataFrameReader` peeks at the first line of the file to grab this information, triggering a job.\n\n#### `\"inferSchema\"`\n- The `\"inferSchema\"` option will scan the file to assign types to each column.\n- Without this option, all columns will be assigned the `StringType`.\n- The `DataFrameReader` will scan the entire contents of the file to determine which type to infer, triggering a job."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a9481cd5-d351-4c42-b3ac-e86c7b4cd51b"}}},{"cell_type":"code","source":["tempDF.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"07e2fdfc-09ca-440c-a9e9-88cbac3b7916"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- _c0: integer (nullable = true)\n |-- Sepal.Length: double (nullable = true)\n |-- Sepal.Width: double (nullable = true)\n |-- Petal.Length: double (nullable = true)\n |-- Petal.Width: double (nullable = true)\n |-- Species: string (nullable = true)\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- _c0: integer (nullable = true)\n-- Sepal.Length: double (nullable = true)\n-- Sepal.Width: double (nullable = true)\n-- Petal.Length: double (nullable = true)\n-- Petal.Width: double (nullable = true)\n-- Species: string (nullable = true)\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Writing to Files\n\nIn many cases the changes applied through DataFrame or SQL actions will need to be persisted. By writing files to disk, this data can easily be passed between sessions and shared with other users.\n\n### The Parquet File Format\n\nParquet is the default file format when working with Spark. Parquet is a columnar format that is supported by many data processing systems. Spark is optimized to perform operations on parquet files (note that the Delta Lake format is built on top of parquet). Spark SQL provides support for both reading and writing Parquet files that automatically preserves the schema of the original data. When writing Parquet files, **all columns are automatically converted to be nullable for compatibility reasons.**\n\nMore discussion on <a href=\"http://parquet.apache.org/documentation/latest/\" target=\"_blank\">Parquet</a>\n\n### Write Options\n\nThere are [many write options](https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/DataFrameWriter.html), and writing to some integrated services will require specific esoteric options to be passed. The syntax in the cell below is the most minimal but explicit example of using DataFrames to save data. Here, the data and schema currently associated with `irisDF` will be persisted in the directory specified by the `outputFilePath`.\n\n#### `format`\nMuch like the DataFrameReader, the DataFrameWriter accepts a wide range of formats. It also supports use of a few file-specific methods (`json`, `parquet`, `csv`) in place of the `.save` syntax.\n\n#### `mode`\nSpark has several [save modes](https://spark.apache.org/docs/latest/sql-data-sources-load-save-functions.html#save-modes).\n\n| mode | details |\n| --- | --- |\n| `\"error\"` | **DEFAULT**; will raise an error message if data already exists at the specified path. |\n| `\"overwrite\"` | If data exists in the target path, it will be deleted before the new data is saved. (This is used heavily throughout the course so that lessons or individual cells may be re-run without conflict.) |\n| `\"append\"` | If data exists in the target path, new data to be saved will be appended to existant data. |\n| `\"ignore\"` | If data exists in the target path, new data will **NOT** be saved. |"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"17d94d55-fa52-49bf-98a0-f33efc48bdf8"}}},{"cell_type":"code","source":["from pyspark.sql.types import DoubleType, IntegerType, StringType, StructField, StructType\n\ncsvSchema = StructType([\n  StructField(\"index\", IntegerType()),\n  StructField(\"sepal_length\", DoubleType()),\n  StructField(\"sepal_width\", DoubleType()),\n  StructField(\"petal_length\", DoubleType()),\n  StructField(\"petal_width\", DoubleType()),\n  StructField(\"species\", StringType())\n])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1209a3e0-3901-40ef-946d-7e0d78bccbc2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["irisDF = (spark.read\n  .option('header', 'true')\n  .schema(csvSchema)          # Use the specified schema\n  .csv(csvFilePath)\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8e7bcf57-4a8a-4e25-904c-27e186056db4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"irisDF","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"index","nullable":true,"type":"integer"},{"metadata":{},"name":"sepal_length","nullable":true,"type":"double"},{"metadata":{},"name":"sepal_width","nullable":true,"type":"double"},{"metadata":{},"name":"petal_length","nullable":true,"type":"double"},{"metadata":{},"name":"petal_width","nullable":true,"type":"double"},{"metadata":{},"name":"species","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["outputFilePath = f\"{userhome}/iris\"\n\n(irisDF\n  .write\n  .format(\"parquet\")\n  .mode(\"overwrite\")\n  .save(outputFilePath))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b19f73cd-a268-456f-a3a6-114ea5c52001"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["display(dbutils.fs.ls(outputFilePath))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f639e425-422a-4940-956e-0855acd740af"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["dbfs:/user/saxaa004678@saipem.com/iris/_SUCCESS","_SUCCESS",0],["dbfs:/user/saxaa004678@saipem.com/iris/_committed_492298399972327579","_committed_492298399972327579",121],["dbfs:/user/saxaa004678@saipem.com/iris/_started_492298399972327579","_started_492298399972327579",0],["dbfs:/user/saxaa004678@saipem.com/iris/part-00000-tid-492298399972327579-64cdd91a-f7e5-4f74-a604-3b5d54328f4f-6-1-c000.snappy.parquet","part-00000-tid-492298399972327579-64cdd91a-f7e5-4f74-a604-3b5d54328f4f-6-1-c000.snappy.parquet",3497]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"path","type":"\"string\"","metadata":"{}"},{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"size","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/user/saxaa004678@saipem.com/iris/_SUCCESS</td><td>_SUCCESS</td><td>0</td></tr><tr><td>dbfs:/user/saxaa004678@saipem.com/iris/_committed_492298399972327579</td><td>_committed_492298399972327579</td><td>121</td></tr><tr><td>dbfs:/user/saxaa004678@saipem.com/iris/_started_492298399972327579</td><td>_started_492298399972327579</td><td>0</td></tr><tr><td>dbfs:/user/saxaa004678@saipem.com/iris/part-00000-tid-492298399972327579-64cdd91a-f7e5-4f74-a604-3b5d54328f4f-6-1-c000.snappy.parquet</td><td>part-00000-tid-492298399972327579-64cdd91a-f7e5-4f74-a604-3b5d54328f4f-6-1-c000.snappy.parquet</td><td>3497</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Laziness By Design\n\nFundamental to Apache Spark are the notions that\n* Transformations are **LAZY**\n* Actions are **EAGER**\n\nThe following code condenses the logic from the preceding lab and uses the DataFrames API to:\n- Specify a schema, format, and file source for the data to be loaded\n- Select columns to `GROUP BY`\n- Aggregate with a `COUNT`\n- Provide an alias name for the aggregate output\n- Specify a column to sort on\n\nThis cell defines a series of **transformations**. By definition, this logic will result in a DataFrame and will not trigger any jobs."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"142badeb-d1ba-43f9-b54e-b3aa18d231b7"}}},{"cell_type":"code","source":["schemaDDL = \"NAME STRING, STATION STRING, LATITUDE FLOAT, LONGITUDE FLOAT, ELEVATION FLOAT, DATE DATE, UNIT STRING, TAVG FLOAT\"\n\nsourcePath = \"/mnt/training/weather/StationData/stationData.parquet/\"\n\ncountsDF = (spark.read\n  .format(\"parquet\")\n  .schema(schemaDDL)\n  .load(sourcePath)\n  .groupBy(\"NAME\", \"UNIT\").count()\n  .withColumnRenamed(\"count\", \"counts\")\n  .orderBy(\"NAME\")\n)\n\ncountsDF"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6baab424-a257-47e3-b4c0-6fbd9bc612bc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"countsDF","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"NAME","nullable":true,"type":"string"},{"metadata":{},"name":"UNIT","nullable":true,"type":"string"},{"metadata":{},"name":"counts","nullable":false,"type":"long"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">Out[18]: DataFrame[NAME: string, UNIT: string, counts: bigint]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[18]: DataFrame[NAME: string, UNIT: string, counts: bigint]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Because `display` is an **action**, a job _will_ be triggered, as logic is executed against the specified data to return a result."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6d039970-4868-4c6b-ae7f-bc83806b93e1"}}},{"cell_type":"code","source":["display(countsDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"84445524-3f68-46c2-9f73-71e8aa79ca33"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["BARNABY CALIFORNIA, CA US","C",151],["BIG ROCK CALIFORNIA, CA US","C",151],["BLACK DIAMOND CALIFORNIA, CA US","C",151],["BRIONES CALIFORNIA, CA US","F",151],["CONCORD BUCHANAN FIELD, CA US","F",149],["HAYWARD AIR TERMINAL, CA US","F",149],["HOUSTON INTERCONTINENTAL AIRPORT, TX US","F",150],["HOUSTON WILLIAM P HOBBY AIRPORT, TX US","C",150],["LAS TRAMPAS CALIFORNIA, CA US","C",151],["LOS PRIETOS CALIFORNIA, CA US","F",151],["MERRITT ISLAND FLORIDA, FL US","C",151],["OAKLAND NORTH CALIFORNIA, CA US","F",151],["OAKLAND SOUTH CALIFORNIA, CA US","F",151],["PULGAS CALIFORNIA, CA US","F",151],["SAN FRANCISCO INTERNATIONAL AIRPORT, CA US","C",149],["SPRING VALLEY CALIFORNIA, CA US","F",151],["WOODACRE CALIFORNIA, CA US","F",151]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"NAME","type":"\"string\"","metadata":"{}"},{"name":"UNIT","type":"\"string\"","metadata":"{}"},{"name":"counts","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>NAME</th><th>UNIT</th><th>counts</th></tr></thead><tbody><tr><td>BARNABY CALIFORNIA, CA US</td><td>C</td><td>151</td></tr><tr><td>BIG ROCK CALIFORNIA, CA US</td><td>C</td><td>151</td></tr><tr><td>BLACK DIAMOND CALIFORNIA, CA US</td><td>C</td><td>151</td></tr><tr><td>BRIONES CALIFORNIA, CA US</td><td>F</td><td>151</td></tr><tr><td>CONCORD BUCHANAN FIELD, CA US</td><td>F</td><td>149</td></tr><tr><td>HAYWARD AIR TERMINAL, CA US</td><td>F</td><td>149</td></tr><tr><td>HOUSTON INTERCONTINENTAL AIRPORT, TX US</td><td>F</td><td>150</td></tr><tr><td>HOUSTON WILLIAM P HOBBY AIRPORT, TX US</td><td>C</td><td>150</td></tr><tr><td>LAS TRAMPAS CALIFORNIA, CA US</td><td>C</td><td>151</td></tr><tr><td>LOS PRIETOS CALIFORNIA, CA US</td><td>F</td><td>151</td></tr><tr><td>MERRITT ISLAND FLORIDA, FL US</td><td>C</td><td>151</td></tr><tr><td>OAKLAND NORTH CALIFORNIA, CA US</td><td>F</td><td>151</td></tr><tr><td>OAKLAND SOUTH CALIFORNIA, CA US</td><td>F</td><td>151</td></tr><tr><td>PULGAS CALIFORNIA, CA US</td><td>F</td><td>151</td></tr><tr><td>SAN FRANCISCO INTERNATIONAL AIRPORT, CA US</td><td>C</td><td>149</td></tr><tr><td>SPRING VALLEY CALIFORNIA, CA US</td><td>F</td><td>151</td></tr><tr><td>WOODACRE CALIFORNIA, CA US</td><td>F</td><td>151</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Actions\n\n\n\nIn production code, actions will generally **write data to persistent storage** using the DataFrameWriter discussed in the preceding notebooks.\n\nDuring interactive code development in Databricks notebooks, the `display` method will frequently be used to **materialize a view of the data** after logic has been applied.\n\nA number of other actions provide the ability to return previews or specify physical execution plans for how logic will map to data. For the complete list, review the [API docs](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset).\n\n| Method | Return | Description |\n|--------|--------|-------------|\n| `collect()` | Collection | Returns an array that contains all of Rows in this Dataset. |\n| `count()` | Long | Returns the number of rows in the Dataset. |\n| `first()` | Row | Returns the first row. |\n| `foreach(f)` | - | Applies a function f to all rows. |\n| `foreachPartition(f)` | - | Applies a function f to each partition of this Dataset. |\n| `head()` | Row | Returns the first row. |\n| `reduce(f)` | Row | Reduces the elements of this Dataset using the specified binary function. |\n| `show(..)` | - | Displays the top 20 rows of Dataset in a tabular form. |\n| `take(n)` | Collection | Returns the first n rows in the Dataset. |\n| `toLocalIterator()` | Iterator | Return an iterator that contains all of Rows in this Dataset. |\n\n<img alt=\"Caution\" title=\"Caution\" style=\"vertical-align: text-bottom; position: relative; height:1.3em; top:0.0em\" src=\"https://files.training.databricks.com/static/images/icon-warning.svg\"/> Actions such as `collect` can lead to out of memory errors by forcing the collection of all data."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3aea652e-de02-4a99-9d17-5b78592df9fd"}}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Transformations\n\nTransformations have the following key characteristics:\n* They eventually return another `DataFrame`.\n* They are immutable - that is each instance of a `DataFrame` cannot be altered once it's instantiated.\n  * This means other optimizations are possible - such as the use of shuffle files (to be discussed in detail later)\n* Are classified as either a Wide or Narrow operation\n\nMost operations in Spark are **transformations**. While many transformations are [DataFrame operations](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset), writing efficient Spark code will require importing methods from the `sql.functions` module, which contains [transformations corresponding to SQL built-in operations](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2884836f-d1f9-4337-a402-99a489f1e2bc"}}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Narrow Transformations\n\nThe data required to compute the records in a single partition reside in at most one partition of the parent RDD.\n\nExamples include:\n* `filter(..)`\n* `drop(..)`\n* `coalesce()`\n\n![](https://databricks.com/wp-content/uploads/2018/05/Narrow-Transformation.png)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b3bb4847-4049-4669-941b-5cc20c698c69"}}},{"cell_type":"code","source":["from pyspark.sql.functions import col\n\ndisplay(countsDF.filter(col(\"NAME\").like(\"%TX%\")))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"00ebc307-83cb-4e10-807a-ce6610e52887"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["HOUSTON INTERCONTINENTAL AIRPORT, TX US","F",150],["HOUSTON WILLIAM P HOBBY AIRPORT, TX US","C",150]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"NAME","type":"\"string\"","metadata":"{}"},{"name":"UNIT","type":"\"string\"","metadata":"{}"},{"name":"counts","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>NAME</th><th>UNIT</th><th>counts</th></tr></thead><tbody><tr><td>HOUSTON INTERCONTINENTAL AIRPORT, TX US</td><td>F</td><td>150</td></tr><tr><td>HOUSTON WILLIAM P HOBBY AIRPORT, TX US</td><td>C</td><td>150</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Wide Transformations\n\nThe data required to compute the records in a single partition may reside in many partitions of the parent RDD. These operations require that data is **shuffled** between executors.\n\nExamples include:\n* `distinct()`\n* `groupBy(..).sum()`\n* `repartition(n)`\n\n![](https://databricks.com/wp-content/uploads/2018/05/Wide-Transformation.png)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e8b4630b-d838-41ca-9c88-89962a80668f"}}},{"cell_type":"code","source":["display(countsDF.groupBy(\"UNIT\").sum(\"counts\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"481f63ae-6207-402c-a33b-23419d05f6eb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["F",1505],["C",1054]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"UNIT","type":"\"string\"","metadata":"{}"},{"name":"sum(counts)","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>UNIT</th><th>sum(counts)</th></tr></thead><tbody><tr><td>F</td><td>1505</td></tr><tr><td>C</td><td>1054</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#That's all folks!"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c6e9f505-f04b-48e7-90af-51b4e36b2558"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"99-scalable-cloud-programming","dashboards":[],"language":"python","widgets":{},"notebookOrigID":1305031661400895}},"nbformat":4,"nbformat_minor":0}
